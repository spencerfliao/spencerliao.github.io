
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Enhancing LLM Visual Reasoning &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css?v=eba8b062" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'llm-reasoning-graphic-puzzles';</script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Multilingual Text Detoxification" href="multilingual-text-detox.html" />
    <link rel="prev" title="N-grams Pattern-mining in Menus" href="codeswitching-corpus-mining_nob.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/logo.jpeg" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="_static/logo.jpeg" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Welcome to my Project Collection
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="etl-for-llm-sales-messaging_nob.html">ETL for AI-Powered Messaging</a></li>
<li class="toctree-l1"><a class="reference internal" href="codeswitching-corpus-mining_nob.html">N-grams Pattern-mining in Menus</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Enhancing LLM Visual Reasoning</a></li>
<li class="toctree-l1"><a class="reference internal" href="multilingual-text-detox.html">Multilingual Text Detoxification</a></li>
<li class="toctree-l1"><a class="reference internal" href="brand.html">Brand Linguistic Insights &amp; Research</a></li>
<li class="toctree-l1"><a class="reference internal" href="design.html">Design Training &amp; Portfolio</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fllm-reasoning-graphic-puzzles.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/llm-reasoning-graphic-puzzles.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Enhancing LLM Visual Reasoning</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-explanation">Corpus + explanation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#our-approach">Our Approach</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#quality-assurance">Quality Assurance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#interface-and-applications">Interface and Applications</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sources">Sources</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-format">Corpus Format</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-collection">Corpus collection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#libraries">Libraries</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#functions">Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithm">Algorithm</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#annotation">Annotation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#description-of-annotations">Description of Annotations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-for-annotation">Tools for Annotation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#annotators">Annotators</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expectations">Expectations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-quality">Data Quality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pilot-study-report">Pilot Study Report</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#annotating-the-materials">Annotating the materials</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data">Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interannotator-agreement-study">Interannotator agreement study</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interannotator-agreement-measure">Interannotator agreement measure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interannotator-score">Interannotator score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#annotation-realiability">Annotation realiability</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experimenting-with-annotation-options">Experimenting with annotation options</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-interface">The Interface</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#justification-of-choices">Justification of Choices</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="enhancing-llm-visual-reasoning">
<h1>Enhancing LLM Visual Reasoning<a class="headerlink" href="#enhancing-llm-visual-reasoning" title="Link to this heading">#</a></h1>
<section id="corpus-explanation">
<h2>Corpus + explanation<a class="headerlink" href="#corpus-explanation" title="Link to this heading">#</a></h2>
<section id="overview">
<h3>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h3>
<p><a class="reference external" href="https://github.com/spencerfliao/llm-reasoning-graphic-puzzles/blob/ed60cff9f7180a37906a4e79e1a0af96ca977586/Slide%20Deck.pdf">View Presentation Slides</a></p>
<p><a class="reference external" href="https://drive.google.com/file/d/1A67JKig9ujmueDwPy8qMMmdqBzqMdZ4s/view?usp=share_link">View Presentation Video</a></p>
<section id="motivation">
<h4>Motivation<a class="headerlink" href="#motivation" title="Link to this heading">#</a></h4>
<p>Large language models (LLMs) struggle with tasks that require abstract, few-shot reasoning—especially in visual domains. The Abstraction and Reasoning Corpus (ARC) provides a benchmark for such tasks, mimicking the kind of generalization humans excel at but machines often fail to replicate.
<img width="976" height="856" alt="Screenshot 2025-07-31 at 18 18 59" src="https://github.com/user-attachments/assets/6b4e98ff-c85f-4f7e-b0db-f17adbb556f9" /></p>
</section>
<section id="our-approach">
<h4>Our Approach<a class="headerlink" href="#our-approach" title="Link to this heading">#</a></h4>
<p>We augment the ARC dataset with structured natural language annotations that describe the underlying logic of each task. Each annotation includes reflections, pixel/object transformations, helper functions, and program instructions. To support this, we convert ARC JSON files into images for easier interpretation and annotation.</p>
</section>
<section id="quality-assurance">
<h4>Quality Assurance<a class="headerlink" href="#quality-assurance" title="Link to this heading">#</a></h4>
<p>To maintain consistency, we conducted an inter-annotator agreement study with a binary correctness evaluation, reaching an agreement score of <strong>85%</strong> across annotators.</p>
</section>
<section id="interface-and-applications">
<h4>Interface and Applications<a class="headerlink" href="#interface-and-applications" title="Link to this heading">#</a></h4>
<p>We also built a searchable interface to explore tasks by reasoning patterns or helper functions. The resulting annotated corpus will be used to fine-tune an LLM capable of solving and explaining ARC tasks autonomously.</p>
</section>
</section>
<hr class="docutils" />
<section id="sources">
<h3>Sources<a class="headerlink" href="#sources" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>ARC Challenge Dataset Source: <a class="reference external" href="https://www.kaggle.com/c/abstraction-and-reasoning-challenge/overview">Kaggle ARC Challenge Dataset</a> (Original source of ARC challenge problems)</p></li>
<li><p>Visual representations of the ARC Dataset: <a class="reference external" href="https://github.ubc.ca/MDS-CL-2023-24/COLX_523_ARCOT/tree/master/data/images">GitHub Repository</a> (Images generated from the ARC dataset to make the task of annotations easier)</p></li>
</ol>
</section>
<section id="corpus-format">
<h3>Corpus Format<a class="headerlink" href="#corpus-format" title="Link to this heading">#</a></h3>
<p>The original ARC dataset is stored in JSON format, designed for compatibility with various machine-learning tools. It is divided into three folders: training, evaluation and test. Each contains multiple JSON files representing distinct reasoning problems, including inputs and outputs designed to test abstract reasoning abilities. The training and evaluation examples also have images corresponding to each JSON file. Each image is a visual representation of a reasoning problem. The human annotations are still a work in progress, so the final storage format and database structure will be determined based on the scalability needs and the ease of access for both machine learning models and researchers. For now we are storing them in TSV files.</p>
</section>
</section>
<section id="corpus-collection">
<h2>Corpus collection<a class="headerlink" href="#corpus-collection" title="Link to this heading">#</a></h2>
<section id="id1">
<h3>Overview<a class="headerlink" href="#id1" title="Link to this heading">#</a></h3>
<p>The code is used to convert JSON files into PNG files, which, along with the human annotations, form a part of the corpus. It processes the training and evaluation data, generates images based on this data, combines these images with specific configurations, and saves the resulting images along with metadata about the data. The format conversion is necessary to provide a visual aid for manually writing the annotations. The code can be found in a Python file named <a class="reference external" href="http://utils.py">utils.py</a>, located inside the src directory at the root level.</p>
</section>
<section id="libraries">
<h3>Libraries<a class="headerlink" href="#libraries" title="Link to this heading">#</a></h3>
<p>The code utilizes several libraries such as json, os, shutil, numpy, pandas, PIL (Python Imaging Library), and matplotlib for file handling, data manipulation, image processing, and image generation, respectively.</p>
</section>
<section id="functions">
<h3>Functions<a class="headerlink" href="#functions" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">load_json(file_path)</span></code>: Loads and returns data from a JSON file. It takes a file path as an argument and returns the parsed JSON data.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">add_margin(pil_img,</span> <span class="pre">top,</span> <span class="pre">right,</span> <span class="pre">bottom,</span> <span class="pre">left,</span> <span class="pre">color)</span></code>: Adds a margin around a PIL image and returns the new image with the margin. It takes various aspects of the margin as arguments.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">delete_directory(path)</span></code>: Deletes a directory at the given path. It handles exceptions to avoid crashes if the directory does not exist or other errors occur during deletion.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">generate_image(array,</span> <span class="pre">file_path,</span> <span class="pre">title)</span></code>: Generates and saves an image based on a 2D array where each element represents a color coded by integers. It maps these integers to specific colors, creates a plotted image with these colors, and saves it to a file path with a given title.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">generate_and_combine_images(data,</span> <span class="pre">output_dir,</span> <span class="pre">filename,</span> <span class="pre">temp_dir='./temp')</span></code>: Processes input data to generate images for training and test datasets, adds margins, combines them horizontally and vertically, and saves the final combined image. It cleans up by deleting temporary images and directories used during processing.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_metadata(input_data)</span></code>: Extracts and returns metadata from the input data, such as the number of rows and columns in the input and output data.</p></li>
</ol>
</section>
<section id="algorithm">
<h3>Algorithm<a class="headerlink" href="#algorithm" title="Link to this heading">#</a></h3>
<ol class="arabic simple">
<li><p>Set up directories for output, training, and evaluation images.</p></li>
<li><p>Iterate over JSON files in the training and evaluation directories.</p></li>
<li><p>For each JSON file:</p>
<ol class="arabic simple">
<li><p>Load the data.</p></li>
<li><p>Generate and combine images based on the data.</p></li>
<li><p>Extract metadata from the data.</p></li>
</ol>
</li>
<li><p>Save the metadata for training and evaluation datasets as CSV files in the specified output directory.</p></li>
</ol>
</section>
</section>
<section id="annotation">
<h2>Annotation<a class="headerlink" href="#annotation" title="Link to this heading">#</a></h2>
<section id="description-of-annotations">
<h3>Description of Annotations<a class="headerlink" href="#description-of-annotations" title="Link to this heading">#</a></h3>
<p>We provide a high-level overview of our annotation process, focusing on human natural language descriptions for each ARC task. Specifically, we generate six sentence-level annotations for each task: Reflection, Pixel Changes, Object Changes, Helper Functions, Overall Pattern, and Program Instructions. Here’s a breakdown of each section:</p>
<ul class="simple">
<li><p>Reflection: Offers a concise abstract overview of the task.</p></li>
<li><p>Pixel Changes: Describes pixel-level relationships between input and output pairs, including movements, color alterations, or pattern variations.</p></li>
<li><p>Object Changes: Defines objects as connected pixel sets, often sharing the same color. This section outlines object-level relationships, covering movements, shapes, counts, sizes, positions, or colors.</p></li>
<li><p>Helper Functions: Lists Python helper functions applicable to each task and suggests their potential use.</p></li>
<li><p>Overall Pattern: Summarizes pixel and object changes, providing a simpler description of the input-output relationship.</p></li>
<li><p>Program Instructions: Offers a plan or pseudocode for writing a Python function to solve the ARC task.</p></li>
</ul>
<p>Informed by Kumar et al.’s findings on neural models learning human inductive bias through natural language abstraction [1], we prioritize abstract descriptions. For instance, if a pattern resembles an axe, we describe it as such rather than focusing on pixel, row, or column specifics. This approach aims to enhance accuracy in solving ARC tasks, leveraging the handcrafted nature of the dataset. However, this method may not be effective for automatically generated ARC tasks.</p>
</section>
<section id="tools-for-annotation">
<h3>Tools for Annotation<a class="headerlink" href="#tools-for-annotation" title="Link to this heading">#</a></h3>
<p>We’ve developed a script to convert all ARC tasks from JSON to images, which are then equally distributed among annotators. Annotation occurs on a shared Google Sheet, facilitating collaboration. Upon completion, the annotations will be exported to a TSV file.</p>
</section>
<section id="annotators">
<h3>Annotators<a class="headerlink" href="#annotators" title="Link to this heading">#</a></h3>
<p>Project team members are responsible for annotations, with each member handling a quarter of the total workload. We opt not to utilize external resources like Mechanical Turk due to the technical nature of the task, expecting higher quality and alignment with our goals from team members’ involvement.</p>
</section>
<section id="expectations">
<h3>Expectations<a class="headerlink" href="#expectations" title="Link to this heading">#</a></h3>
<p>We anticipate annotating approximately 200 ARC tasks in total, with each annotator responsible for 50 annotations. Estimated at 10 minutes per annotation, each annotator will spend approximately 8 hours in total. This estimate is based on a pilot study involving four annotations. Combined with paired data from GPT4 in future work, we believe this dataset will be adequate for bootstrapping a Reinforcement Learning from Human Feedback (RLHF) training on a Large Language Model (LLM).</p>
</section>
<section id="data-quality">
<h3>Data Quality<a class="headerlink" href="#data-quality" title="Link to this heading">#</a></h3>
<p>Pilot studies have been conducted on a few annotations, guiding our annotation approach. Annotators will cross-check each other’s work to maintain high quality. Additionally, annotator training will cover technical details, such as the meaning of helper functions, and ensure consistency in writing style.</p>
</section>
<section id="pilot-study-report">
<h3>Pilot Study Report<a class="headerlink" href="#pilot-study-report" title="Link to this heading">#</a></h3>
<p>We conducted two phases of pilot studies, annotating 14 samples in total. Initially, we focused solely on reflections, but subsequent discussions highlighted issues like data alignment and color representation. In the second trial, we annotated all specified sections, streamlined the process with Google Sheets and image conversion scripts, and refined our annotation style to better suit our goals.</p>
</section>
<section id="annotating-the-materials">
<h3>Annotating the materials<a class="headerlink" href="#annotating-the-materials" title="Link to this heading">#</a></h3>
<p>Annotation guidelines for a task are provided in the form of various sections of instructions, and we will be annotating the sections ourselves.
Some examples of data processed into visually appropriate format and their annotations are shown below: <br></p>
<section id="data">
<h4>Data<a class="headerlink" href="#data" title="Link to this heading">#</a></h4>
<p>The <code class="docutils literal notranslate"><span class="pre">data</span></code> directory contains the following subdirectories:</p>
<ol class="arabic simple">
<li><p><code class="docutils literal notranslate"><span class="pre">references</span></code>: Partial dataset comprising of gpt4 and human annotations that is used as a basis to form the corpus.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">original</span></code>: Original Kaggle dataset comprising of images in the form of .json files, that we use to form our main corpus containing images and the annotations.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">images</span></code>: Images regenerated from the .json files in the <code class="docutils literal notranslate"><span class="pre">original</span></code> folder, that we use for writing the human annotations.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">annotations</span></code>: Annotations for the images in the form of .tsv files.</p></li>
</ol>
</section>
<section id="example">
<h4>Example<a class="headerlink" href="#example" title="Link to this heading">#</a></h4>
<p>The original ARC dataset is stored in JSON format and designed to be compatible with various machine-learning tools. It is divided into three folders: training, evaluation and test. Each contains multiple JSON files representing distinct reasoning problems, including inputs and outputs designed to test abstract reasoning abilities. To make the annotation task more accessible, we converted the JSON files to PNG images. The code for that is present in the <code class="docutils literal notranslate"><span class="pre">src/utils.py</span></code> file. The images, on the other hand, are located in the <code class="docutils literal notranslate"><span class="pre">data/images</span></code> directory. To prevent any data leakage problems, we only converted the training and evaluation  JSON files to images since these are the only files we will be annotating. This aligns with our overall goal: to fine-tune an LLM to automatically generate the annotations for the test set and then use them to solve the ARC reasoning tasks.
Out of the 800 examples (400 training and 400 evaluation), we took 200 and annotated 50. Each annotation consisted of four components: reflections, pixel/object changes, helper functions, and program instructions.</p>
<ol class="arabic simple">
<li><p>Reflections: This part outlines the underlying logic or pattern of the problem, providing a high-level understanding of the solution. It describes how a human might generally approach solving the problem based on the observations made from the inputs and outputs.</p></li>
<li><p>Pixel/Object Changes: Here, we detail the specific alterations made to the objects or pixels within the grid. This includes identifying relevant objects or groups of pixels and describing the changes they undergo, such as movements, colour changes, expansions, or contractions, to achieve the desired output.</p></li>
<li><p>Helper Functions: We list the predefined helper functions used in the solution. These functions perform object detection, colour replacement, grid manipulation, object merging, and so on. These functions serve as building blocks for constructing the step-by-step solution for the reasoning task.</p></li>
<li><p>Program Instructions: This section provides a sequential guide for executing the solution using the previously mentioned helper functions. It is a detailed algorithm that, when followed, would lead from the input grid to the output grid.</p></li>
</ol>
<img width="1503" height="768" alt="Screenshot 2025-07-31 at 18 19 20" src="https://github.com/user-attachments/assets/8bfa716e-15b1-4d53-8f42-9145b11f84ae" />
<p>We decided to store the annotations as TSV files. They are located in the <code class="docutils literal notranslate"><span class="pre">data/annotations</span></code> directory.
These annotations will fine-tune an LLM using Chain of Thought Prompting and Thought Cloning. The goal is that for the test set, it can generate its annotations and use them to solve each reasoning task.</p>
</section>
</section>
</section>
<section id="interannotator-agreement-study">
<h2>Interannotator agreement study<a class="headerlink" href="#interannotator-agreement-study" title="Link to this heading">#</a></h2>
<p>Interannotator agreement data files are located at <code class="docutils literal notranslate"><span class="pre">/data/interannotator_agreement</span></code>.</p>
<section id="interannotator-agreement-measure">
<h3>Interannotator agreement measure<a class="headerlink" href="#interannotator-agreement-measure" title="Link to this heading">#</a></h3>
<p>We calculate our interannotator agreement by manually inspecting each data point and giving a correct/incorrect label to each annotation. For each annotation we assign two other annotators for doing the inspection. The interannotator agreement score is calculated by the percentage of correct labels.</p>
<p>This form of agreement is chosen because the nature of our annotation are natural language sentences. We cannot use n-gram or language model based similarities because the focus of our data is in logical deduction, not statistical similarities or semantic similarities. There are no existing model that can evaluate the logical similarity of two annotations realiably. Therefore we choose to annotate a binary agreement score to each annotation, and use the average as the overall score. Moreover the annotators are already well trained and familiar with the dataset, so we can confidently trust the scores given by the annotators.</p>
</section>
<section id="interannotator-score">
<h3>Interannotator score<a class="headerlink" href="#interannotator-score" title="Link to this heading">#</a></h3>
<p>Using the script at <code class="docutils literal notranslate"><span class="pre">/src/inter_annotator_agreement.py</span></code>, we obtained a score of 0.85 out of 1. Which means the annotators agree 85% of our data is accurate.</p>
</section>
<section id="annotation-realiability">
<h3>Annotation realiability<a class="headerlink" href="#annotation-realiability" title="Link to this heading">#</a></h3>
<p>85% is fairly reasonable as our data annotation involves mentally demanding logical deductions in writing appropriate psuedocode using predefined functions. Some details in the thought process might be missed, or the usage of predefined functions might introduce bugs.</p>
</section>
</section>
<section id="experimenting-with-annotation-options">
<h2>Experimenting with annotation options<a class="headerlink" href="#experimenting-with-annotation-options" title="Link to this heading">#</a></h2>
<p>We experimented different forms of annotation during milestone2. Originally our annotation contain the fields <code class="docutils literal notranslate"><span class="pre">Filename</span></code>, <code class="docutils literal notranslate"><span class="pre">Reflections</span></code>, <code class="docutils literal notranslate"><span class="pre">Pixel</span> <span class="pre">Changes</span></code>, <code class="docutils literal notranslate"><span class="pre">Object</span> <span class="pre">Changes</span></code>, <code class="docutils literal notranslate"><span class="pre">Helper</span> <span class="pre">Functions</span></code>, <code class="docutils literal notranslate"><span class="pre">Overall</span> <span class="pre">Pattern</span></code> and <code class="docutils literal notranslate"><span class="pre">Program</span> <span class="pre">Instructions</span></code>. However during our initial annotations, as seen at <code class="docutils literal notranslate"><span class="pre">/data/annotations/archived</span></code>,  we discovered some of the fields are redundant or unclear in purpose. For example, <code class="docutils literal notranslate"><span class="pre">Reflections</span></code> and <code class="docutils literal notranslate"><span class="pre">Overall</span> <span class="pre">Pattern</span></code> are quite similar. They differ in detailness but the difference is not important in downstream tasks. Therefore we choosed to merge them together. We also merged <code class="docutils literal notranslate"><span class="pre">Pixel</span> <span class="pre">Changes</span></code> and <code class="docutils literal notranslate"><span class="pre">Objects</span> <span class="pre">Changes</span></code> to <code class="docutils literal notranslate"><span class="pre">Pixel/Object</span> <span class="pre">Changes</span></code> because most tasks is best described by either one of them.</p>
</section>
<section id="the-interface">
<h2>The Interface<a class="headerlink" href="#the-interface" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p><strong>Search by Description of Reflection:</strong></p>
<ul class="simple">
<li><p><strong>Note:</strong> Users are able to search the corpus by entering keywords or phrases related to the ARC tasks.</p></li>
</ul>
</li>
<li><p><strong>Search by Helper Function:</strong></p>
<ul class="simple">
<li><p><strong>Note:</strong> Another feature is accessing detailed annotations for ARC tasks by helper functions. This allows users to find tasks that are of similar patterns and solutions, which aids in understanding the reasoning behind each task’s solution and to see examples of how to programmatically approach problem-solving.</p></li>
</ul>
</li>
</ol>
<section id="implementation">
<h3>Implementation<a class="headerlink" href="#implementation" title="Link to this heading">#</a></h3>
<ul class="simple">
<li><p><strong>User Interface:</strong> A simple text box will enable users to enter their search terms, with a toggle indicating whether the user wants to search by either options. Results that include the original task image and annotations would be displayed in the order of relevance. (Optional filters, e.g., difficulty level, if we deem it necessary and have the time to develop, could refine searches, enhancing discoverability of relevant tasks.)
<img width="1680" height="940" alt="Screenshot 2025-07-31 at 18 19 26" src="https://github.com/user-attachments/assets/3b64e0fe-07d8-4ac7-9ba5-b89176c809ba" /></p></li>
</ul>
</section>
<section id="justification-of-choices">
<h3>Justification of Choices<a class="headerlink" href="#justification-of-choices" title="Link to this heading">#</a></h3>
<p>Our choice to focus on reflection and helper functions for the annotated search functionality comes from the desire to showcase the depth of human understanding and computational strategies required to solve ARC tasks. “Reflections” give a quick, abstract insight into the problem-solving required, appealing to users interested in the cognitive aspects of the dataset. In contrast, helper functions cater to those more interested in the programming challenge, providing a bridge between abstract reasoning and practical coding exercises.</p>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Kumar, Sreejan, et al. “Using natural language and program abstractions to instill human inductive biases in machines.” Advances in Neural Information Processing Systems 35 (2022): 167-180.</p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="codeswitching-corpus-mining_nob.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">N-grams Pattern-mining in Menus</p>
      </div>
    </a>
    <a class="right-next"
       href="multilingual-text-detox.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Multilingual Text Detoxification</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-explanation">Corpus + explanation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#our-approach">Our Approach</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#quality-assurance">Quality Assurance</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#interface-and-applications">Interface and Applications</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sources">Sources</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-format">Corpus Format</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#corpus-collection">Corpus collection</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id1">Overview</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#libraries">Libraries</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#functions">Functions</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithm">Algorithm</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#annotation">Annotation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#description-of-annotations">Description of Annotations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#tools-for-annotation">Tools for Annotation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#annotators">Annotators</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#expectations">Expectations</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#data-quality">Data Quality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#pilot-study-report">Pilot Study Report</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#annotating-the-materials">Annotating the materials</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#data">Data</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#example">Example</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#interannotator-agreement-study">Interannotator agreement study</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interannotator-agreement-measure">Interannotator agreement measure</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#interannotator-score">Interannotator score</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#annotation-realiability">Annotation realiability</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#experimenting-with-annotation-options">Experimenting with annotation options</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-interface">The Interface</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">Implementation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#justification-of-choices">Justification of Choices</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>